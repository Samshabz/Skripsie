
\chapter{Introduction}
\label{chap:introduction}

\vspace{-1.2cm}



\section{Background}


Unmanned Aerial Vehicles (UAVs) have become indispensable tools in various sectors, including military operations, surveillance, reconnaissance, and intelligence gathering. In South Africa, UAVs play a crucial role in border monitoring and supporting military missions by providing persistent aerial observation \cite{Weiss2024}. Their capability to operate in hazardous or inaccessible areas enhances operational effectiveness and safety.

Despite their widespread use, UAVs predominantly rely on Global Navigation Satellite Systems (GNSS) such as the Global Positioning System (GPS) for navigation and positioning. GNSS operates by utilizing a constellation of satellites that transmit precise time-stamped signals to Earth-based receivers. Each receiver calculates its position by measuring the time delay of signals from multiple satellites, requiring data from at least four satellites to determine its three-dimensional location. While GNSS provides essential Positioning, Navigation, and Timing (PNT) information globally, its reliance on weak, line-of-sight satellite signals introduces significant vulnerabilities \cite{geotab2024gps}.

In recent years, the vulnerabilities of GNSS to jamming and spoofing have become increasingly pronounced. With the advent of more accessible jamming and spoofing technology, intentional GNSS interference is no longer a complex undertaking \cite{khalil2024gnss}. Instances of GNSS jamming and spoofing are particularly prevalent in conflict zones, where adversaries exploit GNSS weaknesses to disrupt or mislead UAV operations. The issue is far from hypothetical; over 1100 daily incidents of aircraft GNSS spoofing alone have been reported worldwide, underscoring the urgency of addressing these vulnerabilities \cite{khalil2024gnss}.

The increasing prevalence of GNSS disruptions has direct implications for national security. Loss of GNSS signals can lead to an inability to locate the UAV, compromising control and potentially resulting in the UAV crashing or being captured. This situation emphasizes the critical need for a safety measure that can ensure the safe return of the UAV following GNSS signal loss \cite{geotab2024gps}.

Various alternative navigation methods have been explored to mitigate complete reliance on Global Navigation Satellite Systems (GNSS). Odometry-based solutions, or inertial measurement units (IMUs) estimate UAV displacement through inertial measurements from accelerometers and gyroscopes; however, they suffer from significant drift over relatively short distances, rendering the location estimates of even high-end IMUs unusable for typical missions \cite{Zhuang2023}. Quantum sensing navigation employs cold atom inertial sensors to achieve superior precision compared to traditional IMUs, but it is often prohibitively expensive and bulky \cite{wright2022cold}. Radio Frequency (RF) communication systems can triangulate UAV positions using ground beacons or cellular towers, yet their effectiveness is limited in remote areas and by the Earth's curvature, restricting their operational range \cite{brewer_line_2024}. Light Detection and Ranging (LIDAR) systems map the ground by emitting laser pulses and measuring their return times to create detailed 3D environmental maps, but they are power-intensive and emit detectable signals, which are undesirable for stealth operations prevalent in military contexts \cite{scoutaerial2024lidar}.

Image-based navigation presents a viable solution that addresses the limitations of the aforementioned methods. This technique involves capturing images of the landscape and comparing them to previously captured reference images using planar transformations. These transformations align two images of the same planar surface based on their features, enabling the estimation of the UAV's orientation and position relative to the reference image. The coordinates and heading of the reference image can then be used to determine the UAV's absolute location and heading. Reference images can be captured during the UAV's outbound path, allowing it to navigate back to base after GNSS denial by retracing its steps. Alternatively, these images can be pre-acquired and stored in a database for real-time navigation \cite{arafat2023vision}.


However, it remains unclear whether image-based systems can effectively operate in the context of UAV navigation. Specifically, it is uncertain whether they can generalize to various terrains and operational conditions, such as varying light levels, while maintaining their accuracy. This study aims to develop a working pipeline for this context and test it on real-world data, thereby addressing these uncertainties and evaluating the viability of image-based navigation as a redundancy measure to GNSS.



\section{Problem Statement}
The increasing frequency of GNSS disruptions due to jamming and spoofing poses a significant threat to UAV operations \cite{geotab2024gps}. Current alternatives to GNSS navigation, such as quantum sensing, odometry, RF communication, and LIDAR, have significant drawbacks: they are either too expensive and bulky, reduce stealth capabilities, or suffer from drift over time \cite{wright2022cold, Zhuang2023, brewer_line_2024, scoutaerial2024lidar}. To address these drawbacks and enhance the safety and effectiveness of national military missions, a comprehensive synthesis and evaluation of an image-based redundancy navigation system is required. Existing studies on image-based UAV navigation lack detailed system setups and fail to evaluate the system practicality across diverse environments and challenging conditions \cite{sim2002integrated, Zhang2024}.

\section{Aim}
The primary aim of this project is to synthesize and evaluate an image-based navigation system for UAVs that estimates their global position in GNSS-denied environments. The approach will leverage images and telemetry data captured prior to GNSS denial, enabling the UAV to navigate back to base by following its outbound path.

\section{Objectives}


1. \textbf{Develop a Localization Pipeline:} Create a pipeline that achieves the highest possible position estimation accuracy while maintaining real-time performance and generalizability.

2. \textbf{Identify the Best Techniques:} Select, integrate, and optimize feature extraction, matching, and planar transformation estimation techniques.

3. \textbf{Evaluate the Method Across Environments:} Assess the system's performance in various terrains and operational conditions to ensure robustness and adaptability.

4. \textbf{Evaluate the Method Under Stressful Conditions:} Test the system's reliability and accuracy under challenging conditions such as low light levels, high-speed movement, and partial occlusions.





\section{Requirements}
\label{sec:requirements}

\textbf{Accuracy:} Achieve a maximum per-image radial location estimation error of less than 10\% of the UAV's displacement between the images across all datasets.

\textbf{Real-Time Performance:} Ensure a maximum processing time of less than 2 seconds for position and heading estimation following GNSS signal loss across all datasets.

Processing of reference images during the outbound journey, while GNSS signal is available, will have a maximum allowed processing time of 5 seconds. Since the navigator does not need to respond at this point, and the landscape changes relatively slowly, a higher capture rate would only result in excessive, nearly identical reference images.


\textbf{Adaptability:} Maintain the accuracy and time constraints across diverse environments without requiring manual parameter adjustments for each environment. 

\section{Scope}
\label{sec:scope}
This project is scoped to ensure feasibility within the given timeframe and resources by making several assumptions and acknowledging limitations. It assumes that the UAV's downward-facing camera remains perfectly aligned and that the UAV's altitude is constant, minimizing perspective distortion and scale changes, respectively. Images are expected to be free from occlusions and significant dynamic movement. The system relies on onboard sensors like IMUs, coupled with acceptable turning rates, to turn around and recapture its path after GNSS signal loss, ensuring over 60\% image overlap between current and reference images. The study focuses on assessing the system's viability using established methods and parameter sets, excluding exhaustive optimization and untrained machine learning methods. The system outputs the estimated position and heading information for navigation assistance based on simulated video footage; it does not integrate with real-world systems.


\section{Data Provisioning}

An agreement was established with an external party to provide real-world flight data from their UAV operations for use prior to the start of this study. However, the data was not provided within the project's timeframe. To proceed, Google Earth data \cite{GoogleEarth} was utilized. It offers free access to high-resolution aerial imagery with 3D terrain features and therefore real-world perspective changes. It also provides latitude and longitude (Lat-Lon) coordinates and heading, closely approximating real-world data.


\section{Structure of the Report}
This report is structured to provide a comprehensive overview of the research undertaken to develop the image-based GNSS redundancy navigation system for UAVs. Chapter 2 reviews the studies related to vision-based navigation solutions and discusses their contextual limitations. Chapter 3 details the methodology, including feature extraction, matching, similarity computation, and planar transformations. Chapter 4 provides a comparative analysis of different methods applicable to each stage of the pipeline. Chapter 5 presents the evaluation of the developed pipeline against the objectives and various operational challenges. Chapter 6 summarizes the project's outcomes and outlines recommendations for future work.



