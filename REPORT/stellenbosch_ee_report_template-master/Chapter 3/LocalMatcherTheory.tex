



\section*{Local Feature Matching Techniques}

Feature matching is a fundamental component in image-based navigation and pose estimation systems. It involves identifying correspondences between features detected in different images, enabling the estimation of geometric transformations such as translation and rotation. These correspondences form the basis for understanding relative movement, orientation, and position between images. Broadly, feature matchers can be categorized into two types: \textbf{local matchers}, which focus on finding the relative pose between two images by matching keypoints within them, and \textbf{global matchers}, which measure image similarity on a broader scale to determine correlations between images.

This chapter evaluates several state-of-the-art local feature matching techniques, specifically BFMatcher, FLANN, and LightGlue. These matchers were chosen as they represent the most effective and widely researched methods in the field with real-world applicability. LightGlue is evaluated alongside SuperPoint in a separate chapter because it is specifically designed to work effectively with neural network-based feature extractors, such as SuperPoint. It would not provide a fair comparison in this chapter, as this evaluation is focused on comparing matchers using the same feature detectors across different parameters. By evaluating LightGlue and SuperPoint together, we can better assess the benefits of this integrated approach, rather than artificially isolating LightGlue's performance with unrelated feature detectors.

\section*{1. Feature Matching Overview and Key Processing Steps}

The feature matching process involves several critical steps, each contributing to the overall accuracy and robustness of the system:

\subsection*{1.1 Key Processing Steps}

The key processing steps for feature matching are summarized below to provide context on how these matchers integrate into the overall pipeline:

\begin{itemize}
    \item \textbf{Prior Step}: Features are extracted from images using methods like ORB or SuperPoint. The quality of keypoints significantly impacts the subsequent matching performance. These are normalized based on the global heading space (True North) for consistency to ensure translations can be transformed into global coordinates.
    \item \textbf{Matching and Filtering}: Keypoints were matched using different feature matchers (e.g., BFMatcher, FLANN, LightGlue). This involved finding correspondences between descriptors from the two images.
    \item \textbf{Search Technique}: The search technique used was k-nearest neighbors (KNN) to find the nearest neighbors of each descriptor, allowing for the application of Lowe's ratio test for better ambiguity removal.
    \item \textbf{Optimization}: Matches were filtered using Lowe's ratio test to remove ambiguous matches, followed by RANSAC filtering to remove outliers. Other techniques were considered.
    \item \textbf{Post step}: The globally normalized (in North-East space) matches were used for translation estimation (pose inference) or global matching techniques for similarity computation, depending on the stage. 
\end{itemize}

These key processing steps provide the context for understanding how local matchers are evaluated and where they fit within the image-based navigation pipeline.

\subsection*{1.2 Search Technique}

The search technique is a crucial component in feature matching, as it is used to find the nearest neighbors of each descriptor in the other image. Based on empirical results, the k-nearest neighbors (KNN) search technique is the most effective method. By returning more than one match, we can compare each of these matches to determine if they are sufficiently different, a process known as Lowe's ratio test. This helps to remove ambiguous matches. Having only one match, such as in Vanilla and Radius Matching, does not account for this, and having more than two does not provide significant gains. Therefore, the value of $k=2$ is used for KNN.

\subsubsection*{Cross-Check Matching}

Cross-check matching performs matching in both directions (from image A to B and from B to A) and retains only matches that are consistent in both directions. This reduces false positives and increases the reliability of matches by a small margin. However, it doubles the stage's computation time, thereby mitigating the marginal benefit. As such, it is not used in this application.

\subsubsection*{Lowe's Ratio Test}

Lowe's ratio test involves comparing the distance of the best match to the distance of the second-best match. If the ratio is below a certain threshold, the match is considered valid. This helps filter out ambiguous matches. The optimal Lowe's ratio threshold was found to be 0.8 for AKAZE and 0.6 for ORB. A higher threshold implies that more ambiguous matches are included, while a lower threshold excludes more matches. This suggests that AKAZE produces more distinct and less ambiguous matches than ORB. Because of the variety in datasets, alike the extractors, certain thresholds require dynamic optimization. In the software, dynamic increasing of the threshold is applied until a certain minimum amount of matches are found. This ensures that across datasets, there are no cases where no matches are found nor unreliable matches are included.



\section*{2. Methods Evaluated}

\subsection*{2.1 Local Feature Matching Techniques}

This chapter specifically evaluates BFMatcher, FLANN, and LightGlue. These matchers were selected as they represent the most widely-used and effective local feature matchers available:

\begin{itemize}
    \item \textbf{BFMatcher}: A brute-force matcher that is effective for small-scale datasets, prioritizing accuracy over computational efficiency.
    \item \textbf{FLANN (Fast Library for Approximate Nearest Neighbors)}: A faster alternative to BFMatcher, designed to handle large datasets by approximating nearest neighbors, making it preferable for real-time applications.
    \item \textbf{LightGlue}: A neural network-based matcher that leverages deep learning for feature correspondence. It balances computational efficiency with robustness to viewpoint, scale, and illumination changes, though its effectiveness is tied to the quality of the training data.
\end{itemize}

These methods were selected based on their popularity, efficacy in practical applications, and relevance to current research. 

\section*{3. Experimental Setup}

The experimental setup was designed to compare the performance of each matcher under realistic conditions. Optimized parameters were used, similar to those tuned for other methods elsewhere, but were deliberately not fully optimized to better observe relative performance in a real-world scenario where there are variances in responses to parameters. The evaluation includes efficiency, accuracy, and robustness testing. 
Tests:
ROBUSTNESS:
limited optimization:
test with generalized dataset parameters / one param for rot/translational matching for every dataset. 
test with default extractor parameters - instability/low kp test and runtime. 
test with no Lowes filtering - match ambiguity and runtime test. 

OPTIMIZATION:
Tests / empirical tests with different parameters for various optimization techniques. 

test with optimized parameters - accuracy and runtime test

\subsection*{3.1 Datasets}

The datasets used in the study included varied scenes with distinct characteristics: CITY1 and CITY2 (The only dataset that does not include both rotation and translation, it only includes translation) for urban environments, ROCKY for rocky terrains, DESERT for challenging desert scenes with few unique points, and AMAZON for dense forest scenes.

\subsection*{3.2 Evaluation Metrics}

The evaluation focused on the Root Mean Square Error (RMSE) of GPS error across different datasets, as well as runtime in seconds. The focus of the experimental setup was on the comparative performance of the matchers under similar conditions. Note, mean heading error was not necessary as the error is passed through the GPS error. Further, there was no access to ground truth heading data for all of these datasets.

\section*{4. Evaluation and Results}










\subsection*{4.2 Robustness Evaluation}



\subsection*{Test 1: Robustness Evaluation Under Limited Post-Filtering}

This robustness test was conducted under conditions of limited post-filtering, meaning the matches produced by BFMatcher and FLANN were not filtered using Lowe's ratio test or any other ambiguity-filtering techniques. However, RANSAC and other downstream methods were still applied to maintain performance levels. The keypoints entering the matching stages were equivalent across the matchers, ensuring a fair comparison. This test aims to observe the differences in results based solely on the matcher's capabilities, without the additional benefit of ambiguity filtering.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \makecell{\textbf{Matcher}} & 
    \makecell{\textbf{Metric} \\ \textbf{Type}} & 
    \makecell{\textbf{CITY1}} & 
    \makecell{\textbf{CITY2}} & 
    \makecell{\textbf{ROCKY}} & 
    \makecell{\textbf{DESERT}} & 
    \makecell{\textbf{AMAZON}} \\
    \hline
    
    \multirow{4}{*}{\makecell{BF}} & 
    \makecell{RMSE \\ GPS Error} & 777.64 & 507.75 & 465.81 & 534.85 & 319.65 \\
    \cline{2-7}
    & \makecell{Runtime \\ (s)} & 140.56 & 145.91 & 115.26 & 108.71 & 192.19 \\
    \cline{2-7}
    & \makecell{Mean \\ Matches} & 9036.15 & 9062.00 & 10416.30 & 6460.95 & 10451.65 \\
    \cline{2-7}
    & \makecell{Mean \\ Keypoints} & 9059.20 & 9041.27 & 10429.07 & 6480.47 & 10479.13 \\
    \hline
    
    \multirow{4}{*}{\makecell{FLANN}} & 
    \makecell{RMSE \\ GPS Error} & 826.73 & 526.42 & 471.96 & 539.96 & 340.21 \\
    \cline{2-7}
    & \makecell{Runtime \\ (s)} & 50.88 & 46.10 & 50.39 & 50.69 & 64.91 \\
    \cline{2-7}
    & \makecell{Mean \\ Matches} & 9045.45 & 9063.75 & 10434.75 & 6507.80 & 10479.50 \\
    \cline{2-7}
    & \makecell{Mean \\ Keypoints} & 9059.20 & 9041.27 & 10429.07 & 6480.47 & 10479.13 \\
    \hline
    \end{tabular}
    \caption{Comparison of BF and FLANN Matchers Across Datasets with No Post-Filtering}
\end{table}

\section*{Observations}
\begin{itemize}
    \item \textbf{Performance Comparison}: BFMatcher demonstrated slightly better accuracy in terms of RMSE compared to FLANN in most datasets. However, the accuracy improvements were marginal relative to the significant increase in computational time. The runtime for BFMatcher was approximately two to three times longer than FLANN across all datasets.
    
    \item \textbf{Matches Found}: The number of matches detected by both matchers was similar, indicating that the difference in performance is primarily due to the quality of the matches rather than quantity. BFMatcher, with its exhaustive approach, produces matches that are of higher quality, leading to better accuracy but at the expense of significantly increased runtime.

    \item \textbf{Implications for Real-Time Applications}: Without post-filtering, the computational load of BFMatcher becomes impractical for real-time or near-real-time applications. FLANN, on the other hand, provides a more efficient balance between accuracy and runtime. The results highlight that the exhaustive nature of BFMatcher only marginally improves accuracy while significantly impacting computational efficiency.

    \item \textbf{So what?} In contexts where runtime is crucial, FLANN remains a preferable choice even without post-filtering, as it maintains competitive accuracy with far lower processing times. BFMatcher may be more appropriate for scenarios requiring high precision and where computational power is not a limiting factor. However, in most practical applications, the minimal accuracy gains of BFMatcher do not justify the drastic increase in runtime.
\end{itemize}





\subsection*{Test 2: Robustness Evaluation to Generalized Detector Thresholds}

This robustness evaluation examines how well BFMatcher and FLANN perform when using generalized detector thresholds, instead of specific tuning for each dataset. The thresholds chosen are those which are optimal for the city dataset, and hence their exclusion from the table below. This kind of evaluation helps assess each matcher's resilience under suboptimal parameter configurations, especially in situations where either a low or high number of matches are found, potentially leading to instability or an abundance of low-quality points. The results are summarized in Table 2.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\makecell{\textbf{Method}} & 
\makecell{\textbf{Metric Type}} & 
\makecell{\textbf{ROCKY}} & 
\makecell{\textbf{DESERT}} & 
\makecell{\textbf{AMAZON}} \\
\hline

\multirow{4}{*}{\makecell{FLANN}} & 
\makecell{RMSE GPS \\ (m)} & 14.55 & 70.41 & 31.53 \\
\cline{2-7}
& \makecell{Runtime \\ (s)}  & 54.47 & 59.32 & 55.71 \\
\cline{2-7}
& \makecell{Mean Matches} & 1408.05 & 526.45 & 579.4 \\
\hline

\multirow{4}{*}{\makecell{BF}} & 
\makecell{RMSE GPS \\ (m)} & 15.35 & 67.10 & 33.55 \\
\cline{2-7}
& \makecell{Runtime \\ (s)} & 226.81 & 112.39 & 210.86 \\
\cline{2-7}
& \makecell{Mean Matches} & 4362.85 & 590.6 & 1901.15 \\
\hline

\end{tabular}
\caption{Comparison of BF and FLANN Matchers Across Datasets under Generalized Detector Thresholds}
\end{table}

\section*{Observations}
\begin{itemize}
    \item \textbf{Performance Comparison}: BFMatcher generally achieved slightly lower RMSE across most datasets, demonstrating a marginally more precise output. BFMatcher also seemed more sensitive to changes in Lowe's threshold, requiring more precise values for each dataset. This lack of generalizability in BFMatcher was accompanied by significantly higher runtimes, which were often four to five times greater compared to FLANN. This suggests that FLANN's approximation technique can provide reasonable accuracy and generalizability with much shorter processing times, which is beneficial for real-time applications.
    
    \item \textbf{Matches Found}: BFMatcher had significantly more matches across all datasets compared to FLANN. While more matches can improve stability in estimation, they also increase the risk of including false positives, or noisy keypoints, and lead to longer runtimes. FLANN, with fewer matches, demonstrated a balance between false positives and stability, while maintaining high speed.
    
    \item \textbf{So what?} For applications where runtime is important, FLANN emerges as the preferable choice due to its faster processing while maintaining competitive accuracy. For highly precise applications where computational power is not a concern, BF may be a better fit. However, the potential for overfitting and the high number of matches raises concerns about its generalizability.
\end{itemize}





\subsection*{4.2 Optimization Techniques Evaluation}

Optimization techniques, including Lowe's ratio test and RANSAC filtering, were evaluated to understand their effects on both accuracy and runtime. Increasing the number of matches can enhance the stability of future estimations; however, it also raises the risk of false positives that do not fit the model, significantly increasing runtime. This is why effective filtering is crucial. Additional techniques such as cross-check matching for BFMatcher, confidence thresholding, and single match inclusion for FLANN were also assessed.


\subsection*{4.2.1 Single Match Inclusion}

For FLANN, the inclusion of single matches was tested. These occur when knn match can only find a single applicable match. BFmatcher, being exhaustive, always returned two matches. The results are shown in Table 4.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\makecell{\textbf{Dataset}} & \makecell{\textbf{Runtime (Single and Dual Matches) (s)}} & \makecell{\textbf{Runtime (Dual Matches Only) (s)}} & \makecell{\textbf{RMSE GPS (Single and Dual Matches) (m)}} & \makecell{\textbf{RMSE GPS (Dual Matches Only) (m)}} \\
\hline
\makecell{\textbf{CITY1}} & 71.75 & 50.62 & 68.27 & 68.27 \\
\hline
\makecell{\textbf{CITY2}} & 52.96 & 57.54 & 22.34 & 19.44 \\
\hline
\makecell{\textbf{ROCKY}} & 59.62 & 65.59 & 27.32 & 27.78 \\
\hline
\makecell{\textbf{DESERT}} & 65.95 & 57.25 & 159.03 & 159.82 \\
\hline
\makecell{\textbf{AMAZON}} & 58.61 & 49.99 & 126.99 & 123.09 \\
\hline
\end{tabular}
\caption{FLANN Matcher with and without Single Match Inclusion}
\end{table}

\textbf{Observations}: Including only dual matches improved runtime and accuracy in cases where there was significant differences between the two. This can be justified by the fact that single matches cannot be filtered based on ambiguity. 



\subsection*{4.2.1 Lowe’s Ratio}
Lowe’s ratio is essential for dynamically removing ambiguous and inaccurate matches from datasets that can significantly affect accuracy. It operates by comparing the two best matches for each keypoint, determining if they are sufficiently different, rather than relying on an absolute distance threshold. This makes it effective in eliminating matches that may be the closest to a given keypoint but are not necessarily the correct match. If a match is merely the nearest but not the most accurate, other similar matches are also likely to be nearby, resulting in a high Lowe’s ratio and the exclusion of the match.

Increasing the number of matches above the standard 2 can improve accuracy by enhancing the stability of the estimation process; however, it also increases the risk of introducing false positives that do not align with the model. Empirical tests showed that adding a third match did not significantly improve accuracy but substantially increased runtime to impractical levels.

Striking a balance in Lowe’s ratio is crucial to obtaining a sufficient number of stable matches without introducing excessive ambiguity or wasting computational resources. Optimal thresholds for Lowe’s ratio were found to vary based on different parameters and methods, with typical values around 0.8 for AKAZE and 0.7 for ORB. However, these static thresholds lacked generalizability across datasets with varying characteristics.

To address this, a dynamic thresholding approach was implemented. If a minimum number of matches was not found, the threshold was incrementally relaxed. While this method provided stability and ensured a baseline number of matches, it still required dataset-specific tuning to achieve optimal results across varying conditions.

In future applications, a more adaptive approach will be required—one that can dynamically adjust the threshold based on the specific environment prior to GPS loss. Such an approach would ensure an optimal number of matches, balancing stability and accuracy, without relying on a predefined minimum number of matches that may be inappropriate for certain datasets.


\subsection*{4.2.2 Other Optimization Techniques}
Considerations were also done for cross-check matching, and confidence based thresholding. Further, RANSAC is utilized and optimized, but this is included in the rotational and translational estimation sections, where they are more relevant. 
Cross-matching was considered for BFMatcher, but was not included due to the significant increase in runtime with minimal accuracy improvements in empirical tests. 
Confidence thresholding was tested for both methods, where either a weighted average of the matches were taken, or only a certain amount was allowed. This confidence is based on the similarity in descriptor space between keypoints which are potential matches. However, it did not lead to significantly more accurate results or faster processing. However, the main concern was that it was extremely volatile to changes in other parameters, methods and datasets. This lack of generalizability made it unsuitable for the application.






\subsection*{4.3 Accuracy and Runtime Evaluation}

The accuracy evaluation focused on RMSE across different datasets for BFMatcher and FLANN, with optimized parameters for each dataset and all other methods, including matching. The results are shown in Table 1.
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \makecell{\textbf{Matcher}} & 
    \makecell{\textbf{Metric Type}} & 
    \makecell{\textbf{CITY1}} & 
    \makecell{\textbf{CITY2}} & 
    \makecell{\textbf{ROCKY}} & 
    \makecell{\textbf{DESERT}} & 
    \makecell{\textbf{AMAZON}} \\
    \hline

    \multirow{2}{*}{\makecell{FLANN}} & 
    \makecell{RMSE GPS \\ (m)} & 56.59 & 4.70 & 14.63 & 71.20 & 32.35 \\
    \cline{2-7}
    & \makecell{Runtime \\ (s)} & 42.72 & 41.61 & 41.96 & 43.42 & 53.62 \\
    \hline
    
    \multirow{2}{*}{\makecell{BF}} & 
    \makecell{RMSE GPS \\ (m)} & 53.89 & 3.79 & 16.36 & 68.64 & 33.24 \\
    \cline{2-7}
    & \makecell{Runtime \\ (s)} & 203.49 & 228.59 & 46.33 & 52.59 & 88.95 \\
    \hline
    

    
    \end{tabular}
    \caption{Comparison of FLANN and BF Matchers Across Datasets (RMSE GPS and Runtime)}
    \end{table}

    \section*{Observations}
\begin{itemize}
    \item \textbf{BF Matcher} is generally more precise but at the cost of significantly longer runtimes, due to its exhaustive search.
    \item \textbf{FLANN Matcher} is faster in all cases, with runtimes roughly half or less compared to BF, but it generally returns slightly higher RMSE values.
    \item Notably, FLANN performs \textbf{better or comparably in RMSE} in some datasets, suggesting possible overfitting of BF parameters to specific datasets.
    \item \textbf{Why?} In both of these tests, Lowe's ratio was tuned to the optimal threshold for one or two datasets. However, this threshold may not be optimal for all datasets; this test inherently tests the generalizability of the matchers.
    \item \textbf{So what?} FLANN offers comparable accuracy returns due to its generalizability and practical speed benefits, making it a good choice for the requirements. Further, FLANN is more suitable for real-time applications and is more scalable if the dataset size increases (e.g., increased resolution or larger search spaces). 
\end{itemize}

\subsection*{Conclusion}

The study demonstrated that KNN matching with Lowe's ratio test, and in later stages RANSAC, provided the most reliable results across different datasets. BFMatcher matcher was generally more accurate and robust than FLANN, however, that marginal benefit was largely outweighed by the significant speed boosts in FLANN. Further, for future applications, the scalability of FLANN is a significant advantage. 
This study also highlighted the nuanced balance between optimization, even when it is seemingly dynamic, and generalizability, where adding or optimizing specific parameters too much might lead to poor performance across datasets. 


\section*{6. Future Work}

Further optimization of these feature matching techniques could involve dynamic, real-time parameter adjustment to adapt to changing environmental conditions. However, one must take care to ensure these techniques remain generalizable across different datasets. The ideal parameter set will learn from, but not overfit to, the image and telemetry data prior to the event when the UAV has loses GPS, as was the case with the camera parameter inference. 





\subsection*{Cross-Checkingx}  

Both matchers were tested with cross-checking to improve accuracy by reducing false positives. Cross-checking ensures that matches are \textbf{mutual} in both directions between two images. However, due to \textbf{noise} and imperfections in real-world data, matching between images is inherently \textbf{asymmetrical}, meaning the top matches in one direction often differ significantly from the top matches in the reverse direction. 

From empirical testing, it was found that only \textbf{FLANN}, not BFMatcher, could potentially achieve reasonable runtime with cross-checking. BFMatcher’s built-in cross-checking was too slow, so FLANN was retrofitted to support cross-checking for further experiments. Despite efforts to optimize this approach, the inherent challenges of asymmetry, noise, and computational costs limited its effectiveness. 

\subsubsection{Initial Approach}  
Initially, cross-checking was applied \textbf{after Lowe’s ratio filtering}, but this approach resulted in poor accuracy across \textbf{4 out of 5 datasets}. The main issue was that Lowe’s ratio filtering, when applied first, was often \textbf{too strict}, leaving only a small subset of matches for cross-checking. Since matches in the two directions are inherently different, only a few mutual matches were retained, resulting in even fewer usable matches. As a result, this approach led to instability and reduced performance. Table~\ref{tab:flann_comparison} compares the results with and without cross-checking applied post-Lowe's ratio filtering.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \textbf{Matcher} & \textbf{Metric Type} & \textbf{CITY1} & \textbf{CITY2} & \textbf{ROCKY} & \textbf{DESERT} & \textbf{AMAZON} \\
    \hline
    \multirow{2}{*}{FLANN (No Cross-Check)} & 
    RMSE GPS (m) & 56.59 & 4.70 & 14.63 & 71.20 & 32.35 \\
    \cline{2-7}
    & Runtime (s) & 42.72 & 41.61 & 41.96 & 43.42 & 53.62 \\
    \hline
    \multirow{2}{*}{FLANN (With Cross-Check)} & 
    RMSE GPS (m) & 70.71 & 7.96 & 23.64 & 41.37 & 44.39 \\
    \cline{2-7}
    & Runtime (s) & 71.60 & 72.28 & 88.99 & 70.98 & 62.28 \\
    \hline
    \end{tabular}
    \caption{Comparison of FLANN with and without Post-Lowe's Cross-Check across Datasets (RMSE GPS and Runtime)}
    \label{tab:flann_comparison}
\end{table}

\subsubsection{Experimenting with Pre- and Post-Lowe’s Filtering}  
To address the issue of losing too many matches through Lowe’s filtering prior to cross-checking, three variations were tested with a combination of \textbf{pre- and post-Lowes filtering}. The goal was to ensure cross-checking had enough valid matches while maintaining a reasonable runtime. However, due to the inherent differences between forward and reverse matches, balancing runtime and accuracy proved challenging.

\begin{itemize}
    \item \textbf{Low, Unidirectional, or No Filtering:}  
    In this approach, minimal filtering was applied to ensure more matches were passed into cross-checking. However, this resulted in an excessively high number of matches, leading to \textbf{poor runtimes}. The computational cost of cross-checking all these matches was too high to be feasible.

    \item \textbf{High Pre-Filtering:}  
    This method aimed to reduce runtime by aggressively filtering matches before cross-checking. However, this approach resulted in too few matches, leading to \textbf{instability} in the estimation process. There was no balance between high and low pre-filtering that could achieve a stable solution.

    \item \textbf{Dynamic Pre-Filtering in Both Directions:}  
    To mitigate the issues with the above approaches, Lowe’s ratio was dynamically incremented until \textbf{3000 matches} were found in both directions. This method was tuned to run within a maximum acceptable runtime of \textbf{2 minutes}. Despite the effort, the accuracy remained worse than no cross-checking in \textbf{4 out of 5 datasets}, showing that the method was not generalizable.
\end{itemize}

\subsubsection{Final Conclusion}  
Ultimately, all tested combinations of \textbf{pre- and post-filtering with cross-checking} failed to outperform \textbf{no cross-checking} in both accuracy and runtime. The inherent \textbf{asymmetry and noise} in real-world matching meant that forward and reverse matches often differed significantly. Any filtering—whether applied before or after cross-checking—inevitably removed valid matches, making it impossible to achieve a balance that was more optimal than simply using FLANN without cross-checking. Additionally, dynamic filtering introduced further instability and unpredictability, especially across different datasets. 

Given the challenges of balancing accuracy, runtime, and generalizability, it was concluded that the most effective solution was to \textbf{avoid cross-checking entirely} and rely on FLANN’s native performance. This highlights the importance of maintaining a balance between computational efficiency and accuracy while accounting for the limitations of real-world data. 





