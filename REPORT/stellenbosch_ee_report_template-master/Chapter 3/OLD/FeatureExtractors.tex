

    







\chapter{Results}

TESTS:
amt of keypoints for a specific runtime that are accepted as good matches
overall accuracy for heading and GPS change estimation



All parameter choices
add a noise test to final results. 




test 1: accuracy on a single dataset for rotational estimation (global matcher), global matching technique, and local matcher. gonna need to split those. say something about the matches are good no matter what  - not a hard task.
So test both methods (Plus neural local) on both stages (2x3 results) on a single dataset - see which is more accurate only. - total time and acc.
test 2: Take the top 3 combinations and test them on all the datasets (or as many as are close together in accuracy) - optimize for datasets - see which is more accurate only. - total time and acc. 
test 3: mess up the parameters and see how it affects the stability of different methods as well as the overall accuracy - stability, acc and time. 
test 4: test whether one performs significantly better than normally when used as the global matcher technique

XXX - note that we dont look at time per extraction as the time of latter stages is affected by the amount and quality of keypoints. So it might extract rubbish faster, but then take longer to match. So we look at total time.
Test 1 and 2 show accuracy. Test 2 and 3 show robustness. 

XXX - need to make a note on why mean heading error is not compared much - it subtends GPS error - and its estimated in this project as we dont have an accurate heading. 

XXX - say we are going to use histograms, its significantly faster, ensures no effects from the global match, could potentially test that after 





However, when trying different data sets etc - and perhaps when trying it with the local matcher, robustness might affect these end results. 

Table 3 shows the results for confidence thresholding applied to AKAZE and ORB detectors.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Threshold} & \multicolumn{2}{c|}{\textbf{AKAZE}} & \multicolumn{2}{c|}{\textbf{ORB}} \\
\hline
& \makecell{\textbf{RMSE GPS (error)}} & \makecell{\textbf{Runtime (s)}} & \makecell{\textbf{RMSE GPS (error)}} & \makecell{\textbf{Runtime (s)}} \\
\hline
\textbf{No Filter} & 61.64 & 42.43 & 46.76 & 35.73 \\
\hline
\textbf{1000} & 49.52 & 49.17 & 47.19 & 53.79 \\
\hline
\textbf{500} & 51.48 & 46.82 & 48.12 & 38.79 \\
\hline
\textbf{300} & 51.48 & 50.13 & 48.47 & 39.01 \\
\hline
\end{tabular}
\caption{RMSE GPS Error and Runtime for AKAZE and ORB with Different Confidence Match Limits}
\end{table}

\textbf{Observations}: AKAZE performed optimally with a threshold of 1000 matches, while ORB performed best with a threshold of 300 matches. AKAZE achieving optimal performance at higher thresholds suggests that its keypoints are more distinctive and less ambiguous than ORB's. This aids the case that AKAZE requires less optimization after extraction than ORB.


NOTE ORB simply does not work on the desert dataset 





Please note that these tests are run without optimal settings - i.e. for debug purposes certain parts run which normally would not. 


Another note, this data is run in debug mode, with many methods running sequentially instead of a single method. Further, this is ran in a high accuracy mode for both, with an aim to get good results for both while keeping the time between methods reasonably similar without moving far off optimal points. 





The first is the rotational estimator, the latter the translational estimator



XXX make note abt dynamic adjustment for ORB - ambig match minimum

XXX note global local is actually rot and translation. Say how rot is used for global matching and translational estimation. 

TEST 1:
 Ideally better points should subtend better estimations on all transformations. 


NOTE that these methods are fully optimized within the constraint of having similar runtimes. However, orb performs optimally at higher speeds naturally - it loses acc with too many forced keypoints. lets note after these initial results we dont want to go down a rabbit hole of optimization as that will take too long. 
This is on datsetrot


datsetrot
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{Rotational stage Detector} & \multicolumn{2}{c|}{\textbf{ORB}} & \multicolumn{2}{c|}{\textbf{AKAZE}} \\ 
        \hline
        \textbf{Translational stage Detector} & \textbf{ORB} & \textbf{AKAZE} & \textbf{ORB} & \textbf{AKAZE} \\ 
        \hline
        \textbf{Mean Global Good Matches} & 661.24 & 661.24 & 736.86 & 736.86 \\ 
        \hline
        \textbf{Mean Local Good Matches} & 898.05 & 12557.3 & 882.3 & 12256.30 \\ 
        \hline
        \textbf{RMSE (GPS Error) (radial)} & 75.78 & 76.18 & 73.31 & 68.94 \\ 
        \hline
        \textbf{MAE (GPS Error)} & 53.02 & 53.53 & 51.30 & 48.31 \\ 
        \hline
        \textbf{Runtime (seconds)} & 31.62 & 73.14 & 47.67 & 68.18 \\ 
        \hline
    \end{tabular}
    \caption{Comparison of Rotational and Translational Inference Methods with Good Matches, Error Metrics, and MAE}
\end{table}


From whats above, we firsly see how AKAZE finds significantly more keypoints than ORB. note the stages are not exactly the same, other parameters have been tuned to find the highest accuracy for the specific task. 
In terms of accuracy, all methods perform well. Because of the difficulty in perfect optimization, and trying to keep the runtime similar, we see that the MAE and RMSE are similar. Therefore, we will test the accuracy on a different dataset. We will keep the parameter set optimized for dataset x and test on dataset y to see how it performs with unoptimized parameters. 




XXX include MAE
XXX test CUDA

ORB performs the best. But note this result is not perfect. Firstly, there are an extremely large number of interdependent parameters which can be optimized for every dataset or dynamically adjusted within datasets for optimal performance. Finding the perfect strategy for dynamic and static adjustment is out of the scope of this project. However, we have found well-optimized parameters wherever possible. 

Test 3:
General robustness. AKAZE worked better out of the box. When using default parameters and only changing the main threshold, AKAZE worked on the low feature desert dataset, while ORB required changing many parameters. 


In order to test robustness, we will use the optimized parameter set for the initial dataset (CPT rotations) on the other 4 datasets, that is, amazon rain forest, desert, city without rotations, and minor rotation rocky environment. 

xxx - we could test non planar, and low - coverage. both not essential as the outcome is relatively obvious. 
xxx - we need to do a dynamic thresholding similar to inference. its not as simple as more or less features. different datasets will perform optimally with different numbers of features. we need a balance between quality and quantity. This must be done through testing errors in forward path and adjusting based on that. not implemented. 
time intensive to iteratively update, can be done - weak to changes in landscape. increasing far abv minimum req kps is best option. but long-term in flight might be better to have a dynamic threshold.
This is the single most sensitive stage. Param choices here are critical. Maybe a benefit to superpoint. 

test across one dataset.     

datset 


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        \makecell{\textbf{Metric}} & \textbf{CityROT} & \textbf{CityTR} & \textbf{Rocky} & \textbf{Desert} & \textbf{Amazon} \\ 
        \hline
        \makecell{\textbf{Mean Global} \\ \textbf{Good Matches}} & 661.24 & 680.56 & 630.29 & 656.40 & 628.30 \\ 
        \hline
        \makecell{\textbf{Mean Local} \\ \textbf{Good Matches}} & 615.35 & 639.75 & 683.90 & 669.55 & 569.15 \\ 
        \hline
        \makecell{\textbf{RMSE - GPS} \\ \textbf{error}} & 75.78 & 18.12 & 28.10 & 357.19 & 76.30 \\ 
        \hline
        \makecell{\textbf{MAE - GPS} \\ \textbf{error}} & 53.02 & 12.51 & 19.84 & 249.82 & 51.86 \\ 
        \hline
        \makecell{\textbf{Runtime} \\ \textbf{(seconds)}} & 35.84 & 36.65 & 31.89 & 26.11 & 33.54 \\ 
        \hline
    \end{tabular}
    \caption{Robustness testing of ORB (Rotational) and ORB (Translational) across datasets with Parameters Optimized for CityROT dataset}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        \makecell{\textbf{Metric}} & \textbf{CityROT} & \textbf{CityTR} & \textbf{Rocky} & \textbf{Desert} & \textbf{Amazon} \\ 
        \hline
        \makecell{\textbf{Mean Global} \\ \textbf{Good Matches}} & 661.24 & 680.56 & 630.29 & \textbf{FAIL} & \textbf{FAIL} \\ 
        \hline
        \makecell{\textbf{Mean Local} \\ \textbf{Good Matches}} & 1000.0 & 1000.0 & 974.05 & \textbf{FAIL} & \textbf{FAIL} \\ 
        \hline
        \makecell{\textbf{RMSE - GPS} \\ \textbf{error}} & 72.44 & 6.32 & 63.77 & \textbf{FAIL} & \textbf{FAIL} \\ 
        \hline
        \makecell{\textbf{MAE - GPS} \\ \textbf{error}} & 50.94 & 4.32 & 43.01 & \textbf{FAIL} & \textbf{FAIL} \\ 
        \hline
        \makecell{\textbf{Runtime} \\ \textbf{(seconds)}} & 64.37 & 157.77 & 60.39 & \textbf{FAIL} & \textbf{FAIL} \\ 
        \hline
    \end{tabular}
    \caption{Robustness testing of ORB (Rotational) and AKAZE (Translational) across datasets with Parameters Optimized for CityROT dataset}
\end{table}


Further tests with AKAZE as the rotational estimator fail in the same cases. Although certain parameter sets will work with AKAZE for all cases, the issue lies in the fact AKAZE takes extensive time already, and said parameter set will cause even more delays. This is because the AKAZE thresholds do not dynamically adjust based on the amount of keypoints in the scene. ORB, however, does. This is a significant advantage of ORB in terms of robustness. 


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        \makecell{\textbf{Metric}} & \textbf{CityROT} & \textbf{CityTR} & \textbf{Rocky} & \textbf{Desert} & \textbf{Amazon} \\ 
        \hline
        \makecell{\textbf{Mean Global} \\ \textbf{Good Matches}} & 661.24 & 680.56 & 630.29 & 656.40 & 628.30 \\ 
        \hline
        \makecell{\textbf{Mean Local} \\ \textbf{Good Matches}} & nan & nan & nan & nan & nan \\ 
        \hline
        \makecell{\textbf{RMSE - GPS} \\ \textbf{error}} & 78.42 & 14.24 & 23.03 & 39.64 & 42.02 \\ 
        \hline
        \makecell{\textbf{MAE - GPS} \\ \textbf{error}} & 55.43 & 9.79 & 16.07 & 27.20 & 28.10 \\ 
        \hline
        \makecell{\textbf{Mean Heading} \\ \textbf{Error}} & 0.90 & 0.016 & 0.17 & 0.88 & 1.97 \\ 
        \hline
        \makecell{\textbf{Runtime} \\ \textbf{(seconds)}} & 106.61 & 120.39 & 109.36 & 115.53 & 108.83 \\ 
        \hline
    \end{tabular}
    \caption{Robustness testing of ORB (Rotational) and SUPERPOINT-LightGlue (Translational) across datasets with Parameters Optimized for CityROT dataset}
\end{table}











\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        \makecell{\textbf{Translational} \\ \textbf{Detector}} & \textbf{CityROT} & \textbf{CityTR} & \textbf{Rocky} & \textbf{Desert} & \textbf{Amazon} \\ 
        \hline
        \textbf{ORB} & 75.78 & 18.12 & 28.10 & 357.19 & 76.30 \\ 
        \hline
        \textbf{AKAZE} & 72.44 & 6.32 & 63.77 & \textbf{FAIL} & \textbf{FAIL} \\ 
        \hline
        \textbf{SUPERPOINT-LightGlue} & 78.42 & 14.24 & 23.03 & 39.64 & 42.02 \\ 
        \hline
    \end{tabular}
    \caption{RMSE (GPS error) for different Translational Detectors (ORB as Rotational Detector) across datasets}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        \makecell{\textbf{Translational} \\ \textbf{Detector}} & \textbf{CityROT} & \textbf{CityTR} & \textbf{Rocky} & \textbf{Desert} & \textbf{Amazon} \\ 
        \hline
        \textbf{ORB} & 35.84 & 36.65 & 31.89 & 26.11 & 33.54 \\ 
        \hline
        \textbf{AKAZE} & 64.37 & 157.77 & 60.39 & \textbf{FAIL} & \textbf{FAIL} \\ 
        \hline
        \textbf{SUPERPOINT-LightGlue} & 106.61 & 120.39 & 109.36 & 115.53 & 108.83 \\ 
        \hline
    \end{tabular}
    \caption{Runtime (seconds) for different Translational Detectors (ORB as Rotational Detector) across datasets}
\end{table}
