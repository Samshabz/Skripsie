Linear regression inferred factor x: 5.037161827087402
Linear regression inferred factor y: 4.496222019195557

All flights at same altitude??? check this thhhen state issues with flying over different land if factors change by above some percent at same altitude. 


if main_dataset_name == "DATSETSAND":
    glob_thresh = 0.000017 if global_detector_choice == 2 else 20000 if global_detector_choice == 1 else 0
    loc_det_thresh = 0.00001 if local_detector_choice == 2 else 20000 if local_detector_choice == 1 else 0

SAND DATASET:
Phase Correlation stability: 1.007 +/- 103085.206
Linear Algebra stability: 1.000 +/- 364.630
Affine stability: 1.038 +/- 515.925
Rigid stability: 0.972 +/- 1219.296
Homography stability: 0.991 +/- 1517.095

Percentage Deviation: [4.64150535] %
Preprocessing Global Detector: AKAZE, Preprocessing Global Matcher: BF, Global Matching Technique: Histogram, Local Detector: AKAZE, Local Matcher: BF
Mean normalized GPS error: [44.31499246]
 Mean Heading Error: 0.8198001154352124
Mean Length of Keypoints: 4857.266666666666
Mean Global Time to Extract Keypoints: 0.2364 s
Mean Number of Good Matches: 300.0
Range of Good Matches: 3951
Time taken to execute The Method: 51.9841 seconds

This dataset involves sparse desert land (insert picture XXX). These lands have minimal unique points and humans would find it difficult to accurately infer rotations and translations visually. The point of this dataset was to only include images of parts of the desert which are very similar. In other words, I did not include any abnormalities e.g., rocks etc which may have made the test neglect the difficulty of the problem. 

Upon testing, the first step was to set the detection threshold for AKAZE about 100 times lower than for other datasets to allow less distinct features in. ORB was unable to detect sufficient quality keypoints given any parameter set. This tells us that, at least with AKAZE, the method is extremely robust to datasets and is able to pick up on nuanced and small features. However, upon tuning the AKAZE threshold it was found that both accuracy and time is highly sensitive to this parameter. There is a small area where one can have both accurate and timely results. This means optimization is key here. 

In general, each dataset needs to be tested with a variety of parameters to find its optimal state. This involves dynamic real-time optimization while GPS signal is present. However, a simpler solution is to dynamically adjust the feature extractor threshold, the most influential parameter, until a certain amount of keypoints are detected. For now, these thresholds have been hard-coded per dataset, but it would not be much effort to make them dynamic (XXX - do if time - dynamic feature extractor). 

In general, most of the time spent is on matching images to find the most similar image. This can be improved by using a very low search radius, and dynamically increasing it until some amount of images are found. However, this risks missing the most similar image if the UAV is either, relatively speaking, flying relatively fast or capturing images rapidly. A set search space ensures more robustness to these factors.





AMAZON rainforest:
This dataset is captured above the trees of the amazon rainforest at xxx km. As with the desert, these images ignore abnormalities and try focus only on extremely similar patterns and features. Upon visual inspection, there are minor gradient changes in the images, as well as a few off-color trees. However, this dataset is the least diverse of all and the repetition in landscapes and patterns might pose problems. 


elif main_dataset_name == "DATSETAMAZ":
glob_thresh = 0.00017 if global_detector_choice == 2 else 20000 if global_detector_choice == 1 else 0
loc_det_thresh = 0.0001 if local_detector_choice == 2 else 20000 if local_detector_choice == 1 else 0

    akaze for both
Phase Correlation stability: 1.338 +/- 86143.013
Linear Algebra stability: 1.000 +/- 73.790
Affine stability: 0.974 +/- 2201.766
Rigid stability: 0.995 +/- 136.996
Homography stability: 1.106 +/- 6131.805

Percentage Deviation: [3.38002234] %
Preprocessing Global Detector: AKAZE, Preprocessing Global Matcher: BF, Global Matching Technique: Histogram, Local Detector: AKAZE, Local Matcher: BF
Mean normalized GPS error: [23.21998024]
 Mean Heading Error: 1.545597672500035
Mean Length of Keypoints: 4083.133333333333
Mean Global Time to Extract Keypoints: 0.2448 s
Mean Number of Good Matches: 300.0
Range of Good Matches: 4968
Time taken to execute The Method: 53.4206 seconds


with orb for both (instead of akaze for both)
Phase Correlation stability: 0.798 +/- 23458.221
Linear Algebra stability: 1.000 +/- 78.854
Affine stability: 1.025 +/- 1454.510
Rigid stability: 0.991 +/- 112.277
Homography stability: 1.102 +/- 6354.499

Percentage Deviation: [3.41184852] %
Preprocessing Global Detector: ORB, Preprocessing Global Matcher: BF, Global Matching Technique: Histogram, Local Detector: ORB, Local Matcher: BF
Mean normalized GPS error: [23.43861876]
 Mean Heading Error: 1.7209986976919993
Mean Length of Keypoints: 4447.866666666667
Mean Global Time to Extract Keypoints: 0.0283 s
Mean Number of Good Matches: 519.2456896551724
Range of Good Matches: 3653
Time taken to execute The Method: 38.4822 seconds



Linear regression inferred factor x: 3.190764904022217
Linear regression inferred factor y: 3.552771806716919 -> This is for amazon dataset.


XXX test below 50\% coverage -ie crop to 512x512 and see if it still works.


As visible, the close to optimal methods perform with sub-5\% accuracy on a variety of datasets including those with minimal visible features. This shows the strength of the latest state of the art solutions in accurately detecting keypoints in almost any landscape. Its important to note that image based navigation cannot work if the environment has a large percentage of movement. For instance, flying over any body of water would not work well. However, it is clear that this method is both robust and accurate; It could definitely be used for reverse waypoint navigation in a variety of environments. Further, with more optimization, I am confident it could reach sub-0.5\% accuracy, as was the case with some datasets. From that, we can see a potential for medium range odometry based navigation. Specifically, that error applies assuming each image is taken at 1km. This implies a drift of 5m every 1km. This implies we can navigate for 200km before we reach a radial 1km error. Thereafter, we could turn back. This can also be significantly improved by increasing the resolution of the images. Further, it could be improved by taking a high amount of images, and cross-validating the estimations. Further, training a dedicated neural network would improve results on specific environments. Ultimately, there is much potential for not only optimization but large improvements in accuracy even above what I considered confident in. Image-based navigation is significantly cheaper than other novel methods to address the problem such as quantum sensors. Further, it is more accurate than traditional odometry methods and less prone to drift. This is a promising method and I am confident it could be used in a variety of applications.