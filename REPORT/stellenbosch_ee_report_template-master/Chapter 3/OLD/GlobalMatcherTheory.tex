

\section*{Global Matchers}

Global matchers are defined as matching techniques which take the entire image as context. They vary widely in their computational efficiency and accuracy. That is, some aim to infer the rotation and translation of the image, while others aim to quickly find the most similar image. In our context, global matchers will be used for the latter purpose. Note that while they can be used for the former purpose, because they take the entire image as context, they are highly noise sensitive, and have widely different performances for different datasets and parameters. 


There are significant amounts of global matching techniques, however, to maintain scope, I will only focus on global matchers that meet the following criteria:



\begin{itemize}
    \item Computationally efficient on a CPU. More specifically, the method shall take less than 1 second to compare at least 10 images. 
    \item Initial tests, which are not shown, show the matcher to be reasonably effective at the given problem after sufficient optimization.
    \item The technique must not require any pre- or live-training.
    \item The entire image context must be both evenly captured and weighted. 





\subsection*{Local detectors and matcher conversion techniques}
Retrofitting local matching techniques to a global matching context involves computing the similarity using the amount of good matches between images. However, this method has two issues in addition to its high computational cost. Firstly, it does not inherently find features evenly across the entire image, leading to loss of full context. Secondly, each patch can have different feature densities leading to asymmetrical position weighting. To combat this, patch or grid matching is used, and the amount of matches per patch is set well below the mean amount of expected matches per patch to ensure thorough and even feature finding across the images. This method is computationally expensive, but it is the most accurate and most robust to distortions and noise. Tests will be conducted on ORB and AKAZE with BF, FLANN AND GRAPH matchers. Machine learning-based models do not have a potential to meet the time requirement, and therefore will not be tested. 

The following methods below inherently require that images are rotationally aligned. Estimating the intra-image rotation is inherently erroneous and as such the following tests inherently account for the rotational invariance of the method. 

\subsection*{Cross-correlation}
Cross-correlation is a global matching technique that compares two images by sliding one over the other and computing the similarity at each position. 

\subsection*{Histograms}  
Histograms compare images by analyzing the distribution of pixel intensities, which represents how many pixels fall into different intensity levels. This method focuses on global color and brightness information.

\subsection*{SSIM (Structural Similarity Index)}  
SSIM compares images based on luminance, contrast, and structural information. 

\subsection*{Phase Correlation}
Phase correlation is a global matching technique that compares images by analyzing the phase difference between the Fourier transforms of the images.

\subsection*{Hashing}
Hashing is a global matching technique that compares images by computing a hash value for each image and comparing the hash values.



\subsection*{Considerations}
To estimate the best match we need to have an accurate rotational estimation. This involves having sufficient features found. However, the more features found, the more computationally expensive the method becomes. Therefore, it is key to consider using the method of each stage that provides sufficient accuracy without being computationally expensive.