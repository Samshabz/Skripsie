Linear regression inferred factor x: 5.037161827087402
Linear regression inferred factor y: 4.496222019195557

All flights at same altitude??? check this thhhen state issues with flying over different land if factors change by above some percent at same altitude. 



This dataset involves sparse desert land (insert picture XXX). These lands have minimal unique points and humans would find it difficult to accurately infer rotations and translations visually. The point of this dataset was to only include images of parts of the desert which are very similar. In other words, I did not include any abnormalities e.g., rocks etc which may have made the test neglect the difficulty of the problem. 

Upon testing, the first step was to set the detection threshold for AKAZE about 100 times lower than for other datasets to allow less distinct features in. ORB was unable to detect sufficient quality keypoints given any parameter set. This tells us that, at least with AKAZE, the method is extremely robust to datasets and is able to pick up on nuanced and small features. However, upon tuning the AKAZE threshold it was found that both accuracy and time is highly sensitive to this parameter. There is a small area where one can have both accurate and timely results. This means optimization is key here. 

In general, each dataset needs to be tested with a variety of parameters to find its optimal state. This involves dynamic real-time optimization while GPS signal is present. However, a simpler solution is to dynamically adjust the feature extractor threshold, the most influential parameter, until a certain amount of keypoints are detected. For now, these thresholds have been hard-coded per dataset, but it would not be much effort to make them dynamic (XXX - do if time - dynamic feature extractor). 

In general, most of the time spent is on matching images to find the most similar image. This can be improved by using a very low search radius, and dynamically increasing it until some amount of images are found. However, this risks missing the most similar image if the UAV is either, relatively speaking, flying relatively fast or capturing images rapidly. A set search space ensures more robustness to these factors.





AMAZON rainforest:
This dataset is captured above the trees of the amazon rainforest at xxx km. As with the desert, these images ignore abnormalities and try focus only on extremely similar patterns and features. Upon visual inspection, there are minor gradient changes in the images, as well as a few off-color trees. However, this dataset is the least diverse of all and the repetition in landscapes and patterns might pose problems. 




DATASET PARAMETERS:
image resolution vs speed accuracy
dataset terrain
xxx


Linear regression inferred factor x: 3.190764904022217
Linear regression inferred factor y: 3.552771806716919 -> This is for amazon dataset.


XXX test below 50\% coverage -ie crop to 512x512 and see if it still works.


As visible, the close to optimal methods perform with sub-5\% accuracy on a variety of datasets including those with minimal visible features. This shows the strength of the latest state of the art solutions in accurately detecting keypoints in almost any landscape. Its important to note that image based navigation cannot work if the environment has a large percentage of movement. For instance, flying over any body of water would not work well. However, it is clear that this method is both robust and accurate; It could definitely be used for reverse waypoint navigation in a variety of environments. Further, with more optimization, I am confident it could reach sub-0.5\% accuracy, as was the case with some datasets. From that, we can see a potential for medium range odometry based navigation. Specifically, that error applies assuming each image is taken at 1km. This implies a drift of 5m every 1km. This implies we can navigate for 200km before we reach a radial 1km error. Thereafter, we could turn back. This can also be significantly improved by increasing the resolution of the images. Further, it could be improved by taking a high amount of images, and cross-validating the estimations. Further, training a dedicated neural network would improve results on specific environments. Ultimately, there is much potential for not only optimization but large improvements in accuracy even above what I considered confident in. Image-based navigation is significantly cheaper than other novel methods to address the problem such as quantum sensors. Further, it is more accurate than traditional odometry methods and less prone to drift. This is a promising method and I am confident it could be used in a variety of applications.





There is also minor perspective distortion (2) due to non-planarities, however this in minimized at altitude. Shearing is negligible, and scaling is not present in the dataset due to scope choices. 


note that water is useless since it moves
note that testing over mountains will not work as large depth variation will cause differences in apparent motion. However, at a good enough height, and if there we limit to rotational and translational freedoms etc, it might work. Rather, wed want to use stereo vision. 

