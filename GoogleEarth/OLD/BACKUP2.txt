


-    def find_best_match(self, image_index, image_space, grid_size=(5, 5), lower_percentile=20, upper_percentile=100-20):
-        print(f"Self detector name: {self.algdetector_name}")
+    def find_best_match(self, image_index, graph_matcher_true, image_space, grid_size=(5, 5), lower_percentile=20, upper_percentile=100-20):
+        print(f"starting match finding")
+        
         """Finds the best matching stored image for the given image index, using homography for rotation correction and grid-based ORB feature matching."""

         # Start timer to measure performance
@@ -256,40 +257,41 @@ class UAVNavigator:

         current_image = pull_image(image_index)
         current_grids = divide_into_grids(current_image, grid_size)
-        keypoints_current, descriptors_current = self.algdetector.get_keydes(current_image)

         for i in image_space:
             if i == image_index:
                 continue

             stored_image = pull_image(i)
-            # compute the keypoints and descriptors for both indices
-
-            keypoints_stored, descriptors_stored = self.algdetector.get_keydes(stored_image)
+            feats_current = self.stored_feats[image_index]

-            detector_choice = 1 if self.algdetector_name == "ORB" else 2
-            matches = self.algglobalmatcher.find_matches(descriptors_current, descriptors_stored, keypoints_current, keypoints_stored, detector_choice, global_matcher_true=1)
+            feats_stored = self.stored_feats[i]

-            good_matches = []
-            for match_pair in matches:
-                if self.graph_matcher_true:
-                    good_matches.append(match_pair)
-                else:
-                    if len(match_pair) == 2:
-                        m, n = match_pair
-                        if m.distance < 0.75 * n.distance:  # Lowe's ratio test, per grid best match find
-                            good_matches.append(m)
+            # Match descriptors between the current image and the stored image
+
+            featsA, featsB, matches = contracted_lightglue(feats_current, feats_stored) 

+             #knnMatch(descriptors_current, descriptors_stored, k=2)
+
+            good_matches = []
+            for match_pair in matches:
+                good_matches.append(match_pair)  # Handle single or list of matches
+
+            if len(good_matches) < 4:
+                print("Warning: Less than 4 matches found.")
+                continue
+            keypoints1 = featsA['keypoints'].cpu().numpy() # the .cpu() is used to move the tensor to the cpu. The .numpy() is used to convert the tensor to a numpy array
+            keypoints2 = featsB['keypoints'].cpu().numpy()
+            matches = matches.cpu().numpy()

-            src_pts = np.float32([keypoints_current[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
-            dst_pts = np.float32([keypoints_stored[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)
+            src_pts = keypoints1[matches[:, 0]]
+            dst_pts = keypoints2[matches[:, 1]]
             shifts = dst_pts - src_pts


             # initial rotating of image.
             if len(good_matches) > 10:
                 # Find homography to estimate transformation
-
                 M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)

                 if M is not None:
@@ -305,28 +307,25 @@ class UAVNavigator:

                     # Perform grid-wise matching
                     for current_grid, stored_grid in zip(current_grids, rotated_grids_stored):
-                        kp_current_grid, descriptors_current_grid = self.algdetector.get_keydes(current_grid)
+                        print(f"starting this loop")
+                        feats_current_grid = self.detector.get_features(current_grid)
                         #detectAndCompute(current_grid, None)
-                        kp_stored_grid, descriptors_stored_grid = self.algdetector.get_keydes(stored_grid)
+                        feats_stored_grid = self.detector.get_features(stored_grid)
                         #.detectAndCompute(stored_grid, None)

-                        if descriptors_current_grid is None or descriptors_stored_grid is None:
+                        if feats_current_grid is None or feats_stored_grid is None:
                             continue

                         # Match descriptors between grids using knnMatch
-                        detector_choice = 1 if self.algdetector_name == "ORB" else 2
-                        matches_grid = self.algglobalmatcher.find_matches(descriptors_current_grid, descriptors_stored_grid, kp_current_grid, kp_stored_grid, detector_choice, global_matcher_true=1)
-
+
+                        # now use lightglue to match
+                        feats_current_grid, feats_stored_grid, matches_grid = contracted_lightglue(feats_current_grid, feats_stored_grid)
+                        # simply set all matches as good matches.
                         good_matches_grid = []
-                        for match_pair in matches_grid:
-                            if self.graph_matcher_true:
-                                good_matches_grid.append(match_pair)
-                            else:
-                                if len(match_pair) == 2:
-                                    m, n = match_pair
-                                    if m.distance < 0.999 * n.distance:  # Lowe's ratio test, per grid best match find
-                                        good_matches_grid.append(m)
-                        # Sum the good matches for each grid
+                        for match in matches_grid:
+                            good_matches_grid.append(match)
+
+
                         total_good_matches += len(good_matches_grid) if len(good_matches_grid) < 50 else 50

                     # Score based on total good matches across all grids
@@ -335,6 +334,7 @@ class UAVNavigator:
                     if score > max_corr_score:
                         max_corr_score = score
                         best_index = i
+                    print(f"get heeere")
         # End timer and calculate time taken
         total_time = time.time() - start_time
